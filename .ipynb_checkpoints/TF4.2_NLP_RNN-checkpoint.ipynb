{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c622a3d3-a69f-4ffd-b5bc-3365e7701dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c528f26-f56d-4132-8bf9-5b7b7f07e060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b65cf-5b76-4953-9039-30c92b62f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# path_to_file = list(files.upload().keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35a9a5f-7c7b-49a0-a0f6-a2bdc08de85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eebac37e-80e9-49dc-a732-7fc292cc7751",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6778816d-8898-4c08-a9c4-fdc995ce7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "def text_to_int(text):\n",
    "  return np.array([char2idx[c] for c in text])\n",
    "\n",
    "text_as_int = text_to_int(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a12cb5-0feb-4e86-869e-890f215bc79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: First Citizen\n",
      "Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "# lets look at how part of our text is encoded\n",
    "print(\"Text:\", text[:13])\n",
    "print(\"Encoded:\", text_to_int(text[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aface9bf-7e07-4325-9ac5-284aec21101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen\n"
     ]
    }
   ],
   "source": [
    "def int_to_text(ints):\n",
    "  try:\n",
    "    ints = ints.numpy()\n",
    "  except:\n",
    "    pass\n",
    "  return ''.join(idx2char[ints])\n",
    "\n",
    "print(int_to_text(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e25fa498-893e-4c46-9bbe-320e6dff641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100  # length of sequence for a training example\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ece410d9-193d-4078-8d62-31b84088eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a54028c-9f88-4454-9a56-3c7fcb47e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):  # for the example: hello\n",
    "    input_text = chunk[:-1]  # hell\n",
    "    target_text = chunk[1:]  # ello\n",
    "    return input_text, target_text  # hell, ello\n",
    "\n",
    "dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54530eea-d7d0-4f4c-b158-3e42f1ff00dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "\n",
      "OUTPUT\n",
      "irst Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You \n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you \n",
      "\n",
      "OUTPUT\n",
      "re all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you k\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(2):\n",
    "  print(\"\\n\\nEXAMPLE\\n\")\n",
    "  print(\"INPUT\")\n",
    "  print(int_to_text(x))\n",
    "  print(\"\\nOUTPUT\")\n",
    "  print(int_to_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca1945b0-1e6e-4747-bfe2-0ee4626cfd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c1a4b92-4669-46f2-906a-3ce25ae306ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           16640     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5330241 (20.33 MB)\n",
      "Trainable params: 5330241 (20.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f881817-f2cd-4943-bf42-02422e137929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46abff0d-a2c8-460c-bfbb-a3a61f6212de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tf.Tensor(\n",
      "[[[ 3.2217591e-03  1.5247524e-03 -2.4622516e-03 ... -2.4434617e-03\n",
      "   -1.7677713e-03 -2.6711852e-03]\n",
      "  [-4.9223891e-04  6.1959992e-03 -3.9856178e-03 ... -6.3368061e-04\n",
      "    1.5522091e-03 -3.4405878e-03]\n",
      "  [ 2.4908890e-03  1.2330646e-03 -1.9472009e-03 ... -1.5200907e-03\n",
      "    8.9847138e-03 -2.2194744e-04]\n",
      "  ...\n",
      "  [ 1.5126989e-03 -4.5105349e-03 -5.1400624e-03 ... -1.6923998e-03\n",
      "    5.8895387e-03 -1.7338274e-03]\n",
      "  [ 6.0948920e-03 -8.4001645e-03  6.1482436e-04 ... -2.4728621e-03\n",
      "    2.8851451e-03 -2.4738822e-03]\n",
      "  [ 9.2289252e-03 -5.0037638e-03 -1.2059130e-03 ... -3.7512495e-03\n",
      "   -5.0428556e-04 -5.2617583e-03]]\n",
      "\n",
      " [[-7.3607666e-03 -3.4376066e-03 -6.0184090e-04 ... -5.9132706e-03\n",
      "    2.2869899e-03  2.8350810e-04]\n",
      "  [-6.1949957e-03 -4.9471473e-03  4.1575353e-03 ... -2.9805126e-03\n",
      "   -2.1657008e-03  2.1809326e-03]\n",
      "  [-5.3906590e-03 -4.9436502e-03 -3.8592210e-03 ...  1.2833287e-03\n",
      "   -1.8244773e-03  1.0555030e-03]\n",
      "  ...\n",
      "  [ 8.4073432e-03  5.0516455e-03 -4.1666911e-03 ...  7.7504455e-03\n",
      "    4.6444619e-03 -4.9471809e-03]\n",
      "  [ 9.3997410e-03  4.1892147e-04  4.9811788e-04 ...  5.8979494e-03\n",
      "    1.1116267e-02  4.9549248e-04]\n",
      "  [ 8.4769893e-03 -4.9654301e-04  1.1099342e-03 ...  3.9026800e-03\n",
      "    9.5102647e-03 -2.2850698e-03]]\n",
      "\n",
      " [[-1.0616670e-03 -7.0159486e-04 -6.1310064e-03 ...  2.8331715e-03\n",
      "   -5.2426965e-04 -1.8890039e-04]\n",
      "  [-3.8708404e-05 -4.5671514e-03 -6.0372627e-03 ...  1.9355428e-03\n",
      "   -2.3157010e-04 -2.4115888e-03]\n",
      "  [ 2.0083543e-03  7.8306801e-04 -1.3719799e-03 ...  3.0211562e-03\n",
      "    4.2687724e-03 -6.0414309e-03]\n",
      "  ...\n",
      "  [ 2.3326345e-03 -2.3688506e-03  2.2132115e-03 ...  1.3654956e-02\n",
      "    1.1327052e-03  8.1292102e-03]\n",
      "  [ 5.0067361e-03 -3.6002845e-03  5.8918251e-03 ...  1.1685391e-02\n",
      "    8.3859619e-03  1.0614703e-02]\n",
      "  [ 1.1381796e-03 -9.5280465e-03  1.4040518e-03 ...  1.4124047e-02\n",
      "    6.8165725e-03  1.2112222e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.9364658e-03 -4.4431975e-03 -4.8772562e-03 ... -1.1534686e-03\n",
      "   -8.7201712e-04 -2.6613910e-04]\n",
      "  [ 5.6100669e-03 -2.2849459e-03 -6.2749591e-03 ... -2.5507498e-03\n",
      "   -3.0541797e-03 -3.1041128e-03]\n",
      "  [ 9.0622716e-04 -9.4912555e-03 -8.3392067e-03 ...  4.0701674e-03\n",
      "   -1.6574173e-03  1.3795891e-04]\n",
      "  ...\n",
      "  [ 7.4307136e-03 -4.2704078e-03 -6.0118055e-03 ...  6.1169118e-03\n",
      "   -4.2859535e-03  1.0732727e-03]\n",
      "  [ 8.9556752e-03 -1.3529861e-03 -4.9577276e-03 ...  3.4330213e-03\n",
      "   -6.1448556e-03 -1.1480791e-03]\n",
      "  [ 6.8473895e-03 -3.7616375e-03 -2.7733704e-03 ...  4.1221222e-03\n",
      "   -5.3593041e-03 -2.9208404e-03]]\n",
      "\n",
      " [[ 3.2217591e-03  1.5247524e-03 -2.4622516e-03 ... -2.4434617e-03\n",
      "   -1.7677713e-03 -2.6711852e-03]\n",
      "  [ 5.3388593e-03 -2.3879823e-03  4.7408068e-04 ... -1.5917791e-03\n",
      "    6.4005260e-03  1.0458396e-03]\n",
      "  [ 4.2663994e-03 -5.5902018e-03 -1.4717390e-03 ... -1.8078766e-03\n",
      "    4.4759000e-03 -2.0467720e-03]\n",
      "  ...\n",
      "  [ 1.4752127e-02  1.0022672e-02 -1.3437738e-03 ...  6.1426451e-03\n",
      "    4.3475297e-03  1.7226103e-03]\n",
      "  [ 1.2651260e-02  8.8249678e-03  1.2152172e-03 ...  3.6203491e-03\n",
      "    4.6476917e-03  4.0204427e-04]\n",
      "  [ 8.4001739e-03  4.2592543e-03  2.5213258e-03 ...  2.6227613e-03\n",
      "    8.2006035e-03 -2.3064646e-03]]\n",
      "\n",
      " [[-2.5843726e-03 -7.7386643e-03 -4.6892096e-03 ...  4.5869444e-03\n",
      "    8.2602515e-04  3.0847457e-03]\n",
      "  [ 3.4845746e-03 -5.7120696e-03 -6.7333155e-04 ...  2.8746561e-03\n",
      "    4.4301996e-04  4.3787491e-03]\n",
      "  [ 4.1519604e-03 -7.7900719e-03 -1.1430326e-03 ...  2.5446168e-03\n",
      "    6.5784529e-04  1.3103066e-03]\n",
      "  ...\n",
      "  [-5.8575151e-03 -1.8395961e-04 -4.6978393e-03 ... -1.9095133e-03\n",
      "    8.6108847e-03  3.8390846e-03]\n",
      "  [-9.1827149e-04  7.5544175e-03 -1.2550608e-03 ... -9.8342961e-04\n",
      "    9.9102417e-03  9.8559749e-04]\n",
      "  [ 5.5974216e-04  4.2412118e-03 -1.9909898e-03 ... -7.6963636e-04\n",
      "    9.5143327e-03 -1.8703395e-03]]], shape=(64, 100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# we can see that the predicition is an array of 64 arrays, one for each entry in the batch\n",
    "print(len(example_batch_predictions))\n",
    "print(example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa149eb1-748e-4d43-9252-30e73a4966f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[[ 0.00322176  0.00152475 -0.00246225 ... -0.00244346 -0.00176777\n",
      "  -0.00267119]\n",
      " [-0.00049224  0.006196   -0.00398562 ... -0.00063368  0.00155221\n",
      "  -0.00344059]\n",
      " [ 0.00249089  0.00123306 -0.0019472  ... -0.00152009  0.00898471\n",
      "  -0.00022195]\n",
      " ...\n",
      " [ 0.0015127  -0.00451053 -0.00514006 ... -0.0016924   0.00588954\n",
      "  -0.00173383]\n",
      " [ 0.00609489 -0.00840016  0.00061482 ... -0.00247286  0.00288515\n",
      "  -0.00247388]\n",
      " [ 0.00922893 -0.00500376 -0.00120591 ... -0.00375125 -0.00050429\n",
      "  -0.00526176]], shape=(100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# lets examine one prediction\n",
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)\n",
    "# notice this is a 2d array of length 100, where each interior array is the prediction for the next character at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63800591-85ec-41e4-8e73-1880b8fbd32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "tf.Tensor(\n",
      "[ 3.2217591e-03  1.5247524e-03 -2.4622516e-03  9.4225950e-04\n",
      "  2.3759895e-03 -2.2070254e-03  6.7259080e-04 -5.0046965e-03\n",
      "  5.6972140e-03  6.5043452e-04  2.7244366e-03 -4.7783130e-03\n",
      "  1.7517485e-03  5.8677178e-03 -4.6826648e-03  2.4422370e-03\n",
      " -5.9176385e-03  4.3382072e-03  3.2972149e-04  4.2118779e-03\n",
      " -7.0028193e-04  6.2521352e-03  5.1949680e-04 -3.6555901e-04\n",
      " -2.0775767e-03  1.5367118e-03 -2.9101335e-03 -6.0551353e-03\n",
      " -5.5260811e-04  3.9057343e-03 -2.9482648e-03  3.2129122e-03\n",
      " -2.8012828e-03  8.3785122e-03 -2.8072144e-03  1.3822550e-03\n",
      " -1.0625415e-03  8.9015253e-04  3.3288621e-03 -3.4367894e-03\n",
      "  6.9700303e-03  1.4862898e-03 -5.1507456e-03  3.6827126e-04\n",
      " -4.0166588e-03 -4.0871054e-03 -2.3769541e-03 -6.2036896e-03\n",
      " -3.2875368e-03 -7.3304283e-05 -1.8304721e-03 -4.8862738e-03\n",
      " -3.1771227e-03  7.2774375e-03  2.9896195e-03 -4.1382173e-03\n",
      " -3.8111485e-03 -5.8880105e-04 -6.8040723e-03  3.3310934e-03\n",
      " -1.6976772e-03  4.2591109e-03 -2.4434617e-03 -1.7677713e-03\n",
      " -2.6711852e-03], shape=(65,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# and finally well look at a prediction at the first timestep\n",
    "time_pred = pred[0]\n",
    "print(len(time_pred))\n",
    "print(time_pred)\n",
    "# and of course its 65 values representing the probabillity of each character occuring next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b822255-260f-4e72-abfb-6f8cc84be4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BTpSqInm&DN,x:!r$IOr!JCqbB!zWdfsJCXsWC&$ffgl&gX.;PQLuD-ezGBN;,goLBEbebT$qbFXfx;RSaqAR$dpJOJhEzwd&Q:D'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)\n",
    "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
    "\n",
    "# now we can reshape that array and convert all the integers to numbers to see the actual characters\n",
    "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
    "predicted_chars = int_to_text(sampled_indices)\n",
    "\n",
    "predicted_chars  # and this is what the model predicted for training sequence 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51e4bfa8-86b3-4501-80be-974676af0ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f1bdd0c-d1d6-481c-b46e-3fb0653d2de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcff98fa-f294-488b-ba28-969c4c747790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1879037-865e-46fe-8ea1-1c2205d3a6ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "172/172 [==============================] - 952s 6s/step - loss: 2.5931\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 868s 5s/step - loss: 1.8942\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 996s 6s/step - loss: 1.6468\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 922s 5s/step - loss: 1.5112\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 905s 5s/step - loss: 1.4281\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 897s 5s/step - loss: 1.3704\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 952s 6s/step - loss: 1.3247\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 960s 6s/step - loss: 1.2856\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 1027s 6s/step - loss: 1.2493\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 1264s 7s/step - loss: 1.2143\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 1144s 7s/step - loss: 1.1795\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 1006s 6s/step - loss: 1.1443\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 1007s 6s/step - loss: 1.1065\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 833s 5s/step - loss: 1.0685\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 766s 4s/step - loss: 1.0296\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 746s 4s/step - loss: 0.9888\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 766s 4s/step - loss: 0.9472\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 769s 4s/step - loss: 0.9066\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 773s 4s/step - loss: 0.8665\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 770s 4s/step - loss: 0.8290\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 780s 5s/step - loss: 0.7918\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 778s 5s/step - loss: 0.7585\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 769s 4s/step - loss: 0.7261\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 780s 5s/step - loss: 0.6964\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 813s 5s/step - loss: 0.6695\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 763s 4s/step - loss: 0.6436\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 768s 4s/step - loss: 0.6220\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 754s 4s/step - loss: 0.6022\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 746s 4s/step - loss: 0.5835\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 746s 4s/step - loss: 0.5683\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 772s 4s/step - loss: 0.5518\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 771s 4s/step - loss: 0.5382\n",
      "Epoch 33/50\n",
      "172/172 [==============================] - 776s 4s/step - loss: 0.5241\n",
      "Epoch 34/50\n",
      "172/172 [==============================] - 759s 4s/step - loss: 0.5143\n",
      "Epoch 35/50\n",
      "172/172 [==============================] - 742s 4s/step - loss: 0.5046\n",
      "Epoch 36/50\n",
      "172/172 [==============================] - 768s 4s/step - loss: 0.4954\n",
      "Epoch 37/50\n",
      "172/172 [==============================] - 763s 4s/step - loss: 0.4866\n",
      "Epoch 38/50\n",
      "172/172 [==============================] - 779s 5s/step - loss: 0.4795\n",
      "Epoch 39/50\n",
      "172/172 [==============================] - 778s 5s/step - loss: 0.4722\n",
      "Epoch 40/50\n",
      "172/172 [==============================] - 763s 4s/step - loss: 0.4663\n",
      "Epoch 41/50\n",
      "172/172 [==============================] - 754s 4s/step - loss: 0.4620\n",
      "Epoch 42/50\n",
      "172/172 [==============================] - 763s 4s/step - loss: 0.4570\n",
      "Epoch 43/50\n",
      "172/172 [==============================] - 771s 4s/step - loss: 0.4520\n",
      "Epoch 44/50\n",
      "172/172 [==============================] - 770s 4s/step - loss: 0.4483\n",
      "Epoch 45/50\n",
      "172/172 [==============================] - 767s 4s/step - loss: 0.4445\n",
      "Epoch 46/50\n",
      "172/172 [==============================] - 777s 5s/step - loss: 0.4389\n",
      "Epoch 47/50\n",
      "172/172 [==============================] - 761s 4s/step - loss: 0.4372\n",
      "Epoch 48/50\n",
      "172/172 [==============================] - 777s 5s/step - loss: 0.4326\n",
      "Epoch 49/50\n",
      "172/172 [==============================] - 847s 5s/step - loss: 0.4306\n",
      "Epoch 50/50\n",
      "172/172 [==============================] - 791s 5s/step - loss: 0.4277\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51d4a2d1-53b0-40c4-a9b7-92768a2cc1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4cb6906-57bf-4ccd-adb4-b1cf9f428ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "019cbf4c-b276-493d-b986-23ad579f720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_num = 10\n",
    "# model.load_weights(tf.train.load_checkpoint(\"./training_checkpoints/ckpt_\" + str(checkpoint_num)))\n",
    "# model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "\n",
    "# Load model weights from the checkpoint\n",
    "checkpoint_num = 10\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "model.load_weights(os.path.join(checkpoint_dir, \"ckpt_\" + str(checkpoint_num)))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cec10be5-e73b-4bd5-b6f3-a7e24c02b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 800\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "    \n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b518f00-3da6-4c16-8558-517718b3c865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type a starting string:  juliet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juliety,\n",
      "A slaughter-men, for that our fall eyes\n",
      "To this end retrected:\n",
      "The flower of the fums ade me as this\n",
      "your path and the meass that will stay tilk.\n",
      "\n",
      "BISHOP OF CAMILLO:\n",
      "I know it age;\n",
      "And where, sweet son, it stand us deal friends.'\n",
      "And sometimes custom, knew our man's that kiss\n",
      "'Thanks they then from my pence whipped with thy scopot: at the\n",
      "Towers of no less, that I may part of pricket,\n",
      "whether 'tis as you are heard's a hour of send;\n",
      "When Isacret and Sut, his eyes son 'Now Bune as he?\n",
      "\n",
      "CURTIS:\n",
      "Thou art this look'd your honour's poor words?\n",
      "\n",
      "CORIOLANUS:\n",
      "Why should be ot bound? it was,\n",
      "Stand's powerful witness, that Lend with thy veisure;\n",
      "The son 'When mane the hundred sides Romeo,\n",
      "you cannot good and Bolingbroke in her days she is.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "Sheep hot, or has needly by the gate\n",
      "Awa\n"
     ]
    }
   ],
   "source": [
    "inp = input(\"Type a starting string: \")\n",
    "print(generate_text(model, inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3091cd10-1926-4e79-9a8f-dc1c4784e044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
