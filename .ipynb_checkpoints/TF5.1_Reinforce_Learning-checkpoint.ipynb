{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad4acfe-479a-4486-979b-c67fa3388922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9485e137-0464-4cdd-8e10-01f4b0de5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Gym environment with the desired render mode\n",
    "env = gym.make(\"FrozenLake-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef992ca-244a-4efb-8717-9ebcf8e0c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.n)   # get number of states\n",
    "print(env.action_space.n)   # get number of actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9af0e85c-c4d2-4074-a7ce-48059623926d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, {'prob': 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()  # reset enviornment to default state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51dfa9cf-d441-4be1-ac97-36e6dbb43681",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = env.action_space.sample()  # get a random action "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96d09390-395a-40a8-a911-cc965504596b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 0.0, False, False, {'prob': 0.3333333333333333})\n",
      "New State: 9\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "Info: False\n",
      "Additional Info: {'prob': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "result = env.step(action)\n",
    "print(result)\n",
    "\n",
    "new_state, reward, done, info, additional_info = result\n",
    "print(\"New State:\", new_state)\n",
    "print(\"Reward:\", reward)\n",
    "print(\"Done:\", done)\n",
    "print(\"Info:\", info)\n",
    "print(\"Additional Info:\", additional_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1be8f060-2432-44e3-a57d-7ebfd34f9f4a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[180, 200, 230],\n",
       "        [180, 200, 230],\n",
       "        [180, 200, 230],\n",
       "        ...,\n",
       "        [180, 200, 230],\n",
       "        [180, 200, 230],\n",
       "        [180, 200, 230]],\n",
       "\n",
       "       [[180, 200, 230],\n",
       "        [204, 230, 255],\n",
       "        [204, 230, 255],\n",
       "        ...,\n",
       "        [204, 230, 255],\n",
       "        [204, 230, 255],\n",
       "        [180, 200, 230]],\n",
       "\n",
       "       [[180, 200, 230],\n",
       "        [235, 245, 249],\n",
       "        [204, 230, 255],\n",
       "        ...,\n",
       "        [204, 230, 255],\n",
       "        [204, 230, 255],\n",
       "        [180, 200, 230]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[180, 200, 230],\n",
       "        [235, 245, 249],\n",
       "        [235, 245, 249],\n",
       "        ...,\n",
       "        [204, 230, 255],\n",
       "        [235, 245, 249],\n",
       "        [180, 200, 230]],\n",
       "\n",
       "       [[180, 200, 230],\n",
       "        [235, 245, 249],\n",
       "        [235, 245, 249],\n",
       "        ...,\n",
       "        [204, 230, 255],\n",
       "        [204, 230, 255],\n",
       "        [180, 200, 230]],\n",
       "\n",
       "       [[180, 200, 230],\n",
       "        [180, 200, 230],\n",
       "        [180, 200, 230],\n",
       "        ...,\n",
       "        [180, 200, 230],\n",
       "        [180, 200, 230],\n",
       "        [180, 200, 230]]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render()   # render the GUI for the enviornment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad731210-4e10-40de-b54f-fe1491671f7f",
   "metadata": {},
   "source": [
    "# Build Q-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ff21b86-16a3-408f-8b8f-4debda79e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gym\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Create the Gym environment with the desired render mode\n",
    "env = gym.make(\"FrozenLake-v1\", render_mode=\"rgb_array\")\n",
    "STATES = env.observation_space.n\n",
    "ACTIONS = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08b7e967-bfb2-4fb2-a016-ea45f39a2e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.zeros((STATES, ACTIONS))  # create a matrix with all 0 values \n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebdcd228-482e-433d-943d-035a73b14e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 2000 # how many times to run the enviornment from the beginning\n",
    "MAX_STEPS = 100  # max number of steps allowed for each run of enviornment\n",
    "\n",
    "LEARNING_RATE = 0.81  # learning rate\n",
    "GAMMA = 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1be84d6-6014-4023-b9f7-a9b214955e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.9  # start with a 90% chance of picking a random action\n",
    "\n",
    "# code to pick action\n",
    "if np.random.uniform(0, 1) < epsilon:  # we will check if a randomly selected value is less than epsilon.\n",
    "    action = env.action_space.sample()  # take random action\n",
    "else:\n",
    "    action = np.argmax(Q[state, :])  # use Q table to pick best action based on current values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fcd7589-0d73-4730-ba9a-2d7a0b3738d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q[state, action] = Q[state, action] + LEARNING_RATE * (reward + GAMMA * np.max(Q[new_state, :]) - Q[state, action])\n",
    "\n",
    "state = 0\n",
    "action = 0\n",
    "# Q[state, action]\n",
    "\n",
    "Q[state, action] = Q[state, action] + LEARNING_RATE * (reward + GAMMA * np.max(Q[new_state, :]) - Q[state, action])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e498d7-fdfd-4cdf-8869-1c09cdc5c70c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
