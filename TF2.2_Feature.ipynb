{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3ac55ece-e625-4aa5-bd38-f74aa01a2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import FeatureSpace\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset.\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n",
    "# y_train = dftrain.pop('survived')\n",
    "# y_eval = dfeval.pop('survived')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "38258184-f8a2-42d7-b4a1-b755be41d2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 10)\n",
      "Using 627 samples for training and 211 for validation and 53 for test\n"
     ]
    }
   ],
   "source": [
    "test_df = dfeval.sample(frac=0.2, random_state=1337)\n",
    "dfeval = dfeval.drop(test_df.index)\n",
    "print(dftrain.shape)\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation and %d for test\"\n",
    "    % (len(dftrain), len(dfeval), len(test_df))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c51a4b70-b9a0-4f2f-9290-1fa15674509f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck   \n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown  \\\n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "730e7067-b965-44bd-8925-b7964179fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"survived\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    # ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(dftrain)\n",
    "val_ds = dataframe_to_dataset(dfeval)\n",
    "test_ds = dataframe_to_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "55f54a29-47a4-46ea-b344-baa0cc90e71c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'sex': <tf.Tensor: shape=(), dtype=string, numpy=b'male'>, 'age': <tf.Tensor: shape=(), dtype=float64, numpy=22.0>, 'n_siblings_spouses': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'parch': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'fare': <tf.Tensor: shape=(), dtype=float64, numpy=7.25>, 'class': <tf.Tensor: shape=(), dtype=string, numpy=b'Third'>, 'deck': <tf.Tensor: shape=(), dtype=string, numpy=b'unknown'>, 'embark_town': <tf.Tensor: shape=(), dtype=string, numpy=b'Southampton'>, 'alone': <tf.Tensor: shape=(), dtype=string, numpy=b'n'>}\n",
      "Survived: tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Survived:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3937d96c-2a1f-40d9-9feb-cde87101f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)\n",
    "test_ds = test_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4a84b674-0b94-4313-a021-e5feb4e1561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_space = FeatureSpace(\n",
    "#     features={\n",
    "#     \"sex\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "#     \"age\": FeatureSpace.float_discretized(num_bins=30),\n",
    "#     \"n_siblings_spouses\": FeatureSpace.float_discretized(num_bins=3),\n",
    "#     \"parch\": FeatureSpace.float_discretized(num_bins=3),\n",
    "#     \"fare\": FeatureSpace.float_discretized(num_bins=3),\n",
    "#     \"class\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "#     \"deck\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "#     \"embark_town\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "#     \"alone\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "#     },\n",
    "#     # Our utility will one-hot encode all categorical\n",
    "#     # features and concat all features into a single\n",
    "#     # vector (one vector per sample).\n",
    "#     output_mode=\"concat\",\n",
    "# )\n",
    "\n",
    "# # Define a dictionary to map feature names to their type specification\n",
    "# feature_names = {\n",
    "#     \"sex\": \"integer_categorical\",\n",
    "#     \"age\": \"float_discretized\",\n",
    "#     \"n_siblings_spouses\": \"float_normalized\",\n",
    "#     \"parch\": \"float_normalized\",\n",
    "#     \"fare\": \"float_normalized\",\n",
    "#     \"class\": \"integer_categorical\",\n",
    "#     \"deck\": \"integer_categorical\",\n",
    "#     \"embark_town\": \"integer_categorical\",\n",
    "#     \"alone\": \"integer_categorical\",\n",
    "# }\n",
    "\n",
    "# feature_names = {\n",
    "#     \"sex\": \"integer_categorical\",  # Assumes sex is a categorical feature with string values\n",
    "#     \"age\": \"float_discretized\",    # Assumes age is a float feature that needs normalization\n",
    "#     \"n_siblings_spouses\": \"float_normalized\",  # Assumes integer feature that needs normalization\n",
    "#     \"parch\": \"float_normalized\",  # Assumes integer feature that needs normalization\n",
    "#     \"fare\": \"float_normalized\",   # Assumes fare is a float feature that needs normalization\n",
    "#     \"class\": \"integer_categorical\",  # Assumes class is a categorical feature with string values\n",
    "#     \"deck\": \"integer_categorical\",   # Assumes deck is a categorical feature with string values\n",
    "#     \"embark_town\": \"integer_categorical\",  # Assumes embark_town is a categorical feature with string values\n",
    "#     \"alone\": \"integer_categorical\",   # Assumes alone is a categorical feature with string values\n",
    "#     # \"survived\": \"integer_categorical\"  # Assumes survived is the target with integer values\n",
    "# }\n",
    "\n",
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        \"sex\": FeatureSpace.string_categorical(),  # Assumes sex is a categorical feature with string values\n",
    "        \"age\": FeatureSpace.float_normalized(),    # Assumes age is a float feature that needs normalization\n",
    "        \"n_siblings_spouses\": FeatureSpace.integer_categorical(),  # Assumes integer feature that needs normalization\n",
    "        \"parch\": FeatureSpace.integer_categorical(),  # Assumes integer feature that needs normalization\n",
    "        \"fare\": FeatureSpace.float_normalized(),   # Assumes fare is a float feature that needs normalization\n",
    "        \"class\": FeatureSpace.string_categorical(),  # Assumes class is a categorical feature with string values\n",
    "        \"deck\": FeatureSpace.string_categorical(),   # Assumes deck is a categorical feature with string values\n",
    "        \"embark_town\": FeatureSpace.string_categorical(),  # Assumes embark_town is a categorical feature with string values\n",
    "        \"alone\": FeatureSpace.string_categorical(),   # Assumes alone is a categorical feature with string values\n",
    "        # \"survived\": \"integer_categorical\"  # Assumes survived is the target with integer values\n",
    "    },\n",
    "    output_mode=\"concat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7116c9cb-87a5-4325-be46-b2405dd09641",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n",
    "feature_space.adapt(train_ds_with_no_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9d956b0b-0afb-4f5c-9d24-b7c005199d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_x.shape: (32, 41)\n",
      "preprocessed_x.dtype: <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "for x, _ in train_ds.take(1):\n",
    "    preprocessed_x = feature_space(x)\n",
    "    print(\"preprocessed_x.shape:\", preprocessed_x.shape)\n",
    "    print(\"preprocessed_x.dtype:\", preprocessed_x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "22677131-3c46-424e-ad65-8761cca959c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_ds = train_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "preprocessed_train_ds = preprocessed_train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "preprocessed_val_ds = val_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "preprocessed_val_ds = preprocessed_val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "preprocessed_test_ds = test_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "preprocessed_test_ds = preprocessed_test_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8fbdb130-8503-4c3f-96bf-6a34bd11f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_inputs = feature_space.get_inputs()\n",
    "# encoded_features = feature_space.get_encoded_features()\n",
    "\n",
    "# sq_model = keras.Sequential()\n",
    "# sq_model.add(keras.layers.Dense(32, activation=\"relu\", input_shape=encoded_features.shape[1:]))\n",
    "# sq_model.add(keras.layers.Dropout(0.5))\n",
    "# sq_model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# sq_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Create the training model\n",
    "dict_inputs = feature_space.get_inputs()\n",
    "encoded_features = feature_space.get_encoded_features()\n",
    "\n",
    "sq_model = keras.Sequential()\n",
    "sq_model.add(keras.layers.Dense(32, activation=\"relu\", input_shape=encoded_features.shape[1:]))\n",
    "sq_model.add(keras.layers.Dropout(0.5))\n",
    "sq_model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "sq_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train your training model (sq_model) with your data here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cced2ded-1a42-4adf-9a35-77ddb3fcb2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 32)                1344      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1377 (5.38 KB)\n",
      "Trainable params: 1377 (5.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e683e11a-5253-4e45-83fd-57aae965a404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "20/20 - 3s - loss: 0.6604 - accuracy: 0.6140 - val_loss: 0.6267 - val_accuracy: 0.6209 - 3s/epoch - 135ms/step\n",
      "Epoch 2/25\n",
      "20/20 - 1s - loss: 0.6304 - accuracy: 0.6475 - val_loss: 0.6025 - val_accuracy: 0.6398 - 566ms/epoch - 28ms/step\n",
      "Epoch 3/25\n",
      "20/20 - 1s - loss: 0.6075 - accuracy: 0.6587 - val_loss: 0.5823 - val_accuracy: 0.6777 - 523ms/epoch - 26ms/step\n",
      "Epoch 4/25\n",
      "20/20 - 1s - loss: 0.5916 - accuracy: 0.7097 - val_loss: 0.5646 - val_accuracy: 0.7204 - 555ms/epoch - 28ms/step\n",
      "Epoch 5/25\n",
      "20/20 - 1s - loss: 0.5608 - accuracy: 0.7289 - val_loss: 0.5478 - val_accuracy: 0.7441 - 547ms/epoch - 27ms/step\n",
      "Epoch 6/25\n",
      "20/20 - 1s - loss: 0.5506 - accuracy: 0.7560 - val_loss: 0.5304 - val_accuracy: 0.7441 - 522ms/epoch - 26ms/step\n",
      "Epoch 7/25\n",
      "20/20 - 1s - loss: 0.5340 - accuracy: 0.7544 - val_loss: 0.5150 - val_accuracy: 0.7773 - 538ms/epoch - 27ms/step\n",
      "Epoch 8/25\n",
      "20/20 - 1s - loss: 0.5266 - accuracy: 0.7911 - val_loss: 0.5023 - val_accuracy: 0.7773 - 535ms/epoch - 27ms/step\n",
      "Epoch 9/25\n",
      "20/20 - 1s - loss: 0.5000 - accuracy: 0.7927 - val_loss: 0.4907 - val_accuracy: 0.7773 - 588ms/epoch - 29ms/step\n",
      "Epoch 10/25\n",
      "20/20 - 1s - loss: 0.4820 - accuracy: 0.8054 - val_loss: 0.4810 - val_accuracy: 0.7820 - 535ms/epoch - 27ms/step\n",
      "Epoch 11/25\n",
      "20/20 - 1s - loss: 0.4945 - accuracy: 0.7783 - val_loss: 0.4732 - val_accuracy: 0.7820 - 715ms/epoch - 36ms/step\n",
      "Epoch 12/25\n",
      "20/20 - 1s - loss: 0.4922 - accuracy: 0.7911 - val_loss: 0.4681 - val_accuracy: 0.7773 - 712ms/epoch - 36ms/step\n",
      "Epoch 13/25\n",
      "20/20 - 0s - loss: 0.4790 - accuracy: 0.7863 - val_loss: 0.4636 - val_accuracy: 0.7725 - 491ms/epoch - 25ms/step\n",
      "Epoch 14/25\n",
      "20/20 - 1s - loss: 0.4902 - accuracy: 0.7911 - val_loss: 0.4597 - val_accuracy: 0.7773 - 529ms/epoch - 26ms/step\n",
      "Epoch 15/25\n",
      "20/20 - 1s - loss: 0.4674 - accuracy: 0.8150 - val_loss: 0.4563 - val_accuracy: 0.7678 - 579ms/epoch - 29ms/step\n",
      "Epoch 16/25\n",
      "20/20 - 1s - loss: 0.4750 - accuracy: 0.7863 - val_loss: 0.4535 - val_accuracy: 0.7725 - 824ms/epoch - 41ms/step\n",
      "Epoch 17/25\n",
      "20/20 - 1s - loss: 0.4630 - accuracy: 0.8166 - val_loss: 0.4514 - val_accuracy: 0.7725 - 641ms/epoch - 32ms/step\n",
      "Epoch 18/25\n",
      "20/20 - 1s - loss: 0.4359 - accuracy: 0.8182 - val_loss: 0.4484 - val_accuracy: 0.7725 - 701ms/epoch - 35ms/step\n",
      "Epoch 19/25\n",
      "20/20 - 1s - loss: 0.4400 - accuracy: 0.8166 - val_loss: 0.4454 - val_accuracy: 0.7725 - 691ms/epoch - 35ms/step\n",
      "Epoch 20/25\n",
      "20/20 - 1s - loss: 0.4700 - accuracy: 0.8118 - val_loss: 0.4432 - val_accuracy: 0.7725 - 542ms/epoch - 27ms/step\n",
      "Epoch 21/25\n",
      "20/20 - 1s - loss: 0.4404 - accuracy: 0.8118 - val_loss: 0.4413 - val_accuracy: 0.7725 - 546ms/epoch - 27ms/step\n",
      "Epoch 22/25\n",
      "20/20 - 1s - loss: 0.4522 - accuracy: 0.8054 - val_loss: 0.4396 - val_accuracy: 0.7773 - 566ms/epoch - 28ms/step\n",
      "Epoch 23/25\n",
      "20/20 - 1s - loss: 0.4506 - accuracy: 0.8086 - val_loss: 0.4381 - val_accuracy: 0.7820 - 521ms/epoch - 26ms/step\n",
      "Epoch 24/25\n",
      "20/20 - 1s - loss: 0.4531 - accuracy: 0.8182 - val_loss: 0.4373 - val_accuracy: 0.7820 - 523ms/epoch - 26ms/step\n",
      "Epoch 25/25\n",
      "20/20 - 1s - loss: 0.4366 - accuracy: 0.8150 - val_loss: 0.4367 - val_accuracy: 0.7820 - 500ms/epoch - 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25998fd8950>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_model.fit(\n",
    "    preprocessed_train_ds, epochs=25, validation_data=preprocessed_val_ds, verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ccbad80e-be78-4792-b9ea-fc249bf72260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 0s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = sq_model.predict(preprocessed_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "912ef60f-74b6-4dc9-b3de-a61065b05596",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88312924]\n",
      " [0.76166606]\n",
      " [0.33288527]\n",
      " [0.11357001]\n",
      " [0.16023742]\n",
      " [0.07630911]\n",
      " [0.11996026]\n",
      " [0.12456548]\n",
      " [0.9754267 ]\n",
      " [0.09192388]\n",
      " [0.6679702 ]\n",
      " [0.11549904]\n",
      " [0.10991735]\n",
      " [0.79428804]\n",
      " [0.7388393 ]\n",
      " [0.4658922 ]\n",
      " [0.9128577 ]\n",
      " [0.5441925 ]\n",
      " [0.80347174]\n",
      " [0.08881468]\n",
      " [0.80342984]\n",
      " [0.17839518]\n",
      " [0.35160193]\n",
      " [0.10838598]\n",
      " [0.09820534]\n",
      " [0.1462464 ]\n",
      " [0.1164173 ]\n",
      " [0.10454416]\n",
      " [0.52648205]\n",
      " [0.10419982]\n",
      " [0.876744  ]\n",
      " [0.19481464]\n",
      " [0.2796858 ]\n",
      " [0.2935987 ]\n",
      " [0.11629638]\n",
      " [0.11545198]\n",
      " [0.09029475]\n",
      " [0.09621318]\n",
      " [0.76231176]\n",
      " [0.4748198 ]\n",
      " [0.16756034]\n",
      " [0.11438232]\n",
      " [0.76260924]\n",
      " [0.23814404]\n",
      " [0.7742723 ]\n",
      " [0.9570616 ]\n",
      " [0.14080954]\n",
      " [0.22503024]\n",
      " [0.60616136]\n",
      " [0.11236387]\n",
      " [0.13690378]\n",
      " [0.54022837]\n",
      " [0.10793312]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3fcf80cf-124f-4c6a-941d-ca3a9d7f6fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (predictions > 0.5).astype(int).reshape(-1,)\n",
    "label_values = []\n",
    "\n",
    "# Iterate through preprocessed_val_ds to collect labels\n",
    "for _, labels in preprocessed_test_ds.as_numpy_iterator():\n",
    "    label_values.extend(labels)\n",
    "\n",
    "# Convert the collected labels to a NumPy array\n",
    "label_values = np.array(label_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f144a4bb-fe32-438e-b521-89b66360d7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84        34\n",
      "           1       0.72      0.68      0.70        19\n",
      "\n",
      "    accuracy                           0.79        53\n",
      "   macro avg       0.78      0.77      0.77        53\n",
      "weighted avg       0.79      0.79      0.79        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_values, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1c7a5c37-1943-4f5b-86b6-45d99009f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_inputs = feature_space.get_inputs()\n",
    "# encoded_features = feature_space.get_encoded_features()\n",
    "\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(encoded_features)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "predictions = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "training_model = keras.Model(inputs=encoded_features, outputs=predictions)\n",
    "training_model.compile(\n",
    "    optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "inference_model = keras.Model(inputs=dict_inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e4694f50-8eaa-484e-b0a0-ca3de6b85dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 41)]              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                1344      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1377 (5.38 KB)\n",
      "Trainable params: 1377 (5.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0f45bfef-eeec-46e2-830b-b963ca91c5d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 - 2s - loss: 0.6938 - accuracy: 0.5694 - val_loss: 0.6283 - val_accuracy: 0.6445 - 2s/epoch - 123ms/step\n",
      "Epoch 2/50\n",
      "20/20 - 1s - loss: 0.6373 - accuracy: 0.6507 - val_loss: 0.5954 - val_accuracy: 0.6777 - 592ms/epoch - 30ms/step\n",
      "Epoch 3/50\n",
      "20/20 - 1s - loss: 0.6147 - accuracy: 0.6715 - val_loss: 0.5703 - val_accuracy: 0.7109 - 707ms/epoch - 35ms/step\n",
      "Epoch 4/50\n",
      "20/20 - 1s - loss: 0.5708 - accuracy: 0.7129 - val_loss: 0.5487 - val_accuracy: 0.7346 - 725ms/epoch - 36ms/step\n",
      "Epoch 5/50\n",
      "20/20 - 1s - loss: 0.5753 - accuracy: 0.7177 - val_loss: 0.5316 - val_accuracy: 0.7488 - 561ms/epoch - 28ms/step\n",
      "Epoch 6/50\n",
      "20/20 - 1s - loss: 0.5446 - accuracy: 0.7321 - val_loss: 0.5160 - val_accuracy: 0.7488 - 522ms/epoch - 26ms/step\n",
      "Epoch 7/50\n",
      "20/20 - 1s - loss: 0.5451 - accuracy: 0.7560 - val_loss: 0.5036 - val_accuracy: 0.7583 - 524ms/epoch - 26ms/step\n",
      "Epoch 8/50\n",
      "20/20 - 0s - loss: 0.5134 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7725 - 467ms/epoch - 23ms/step\n",
      "Epoch 9/50\n",
      "20/20 - 1s - loss: 0.5064 - accuracy: 0.7640 - val_loss: 0.4837 - val_accuracy: 0.7725 - 636ms/epoch - 32ms/step\n",
      "Epoch 10/50\n",
      "20/20 - 1s - loss: 0.4841 - accuracy: 0.7767 - val_loss: 0.4757 - val_accuracy: 0.7678 - 524ms/epoch - 26ms/step\n",
      "Epoch 11/50\n",
      "20/20 - 1s - loss: 0.4928 - accuracy: 0.7847 - val_loss: 0.4691 - val_accuracy: 0.7678 - 594ms/epoch - 30ms/step\n",
      "Epoch 12/50\n",
      "20/20 - 1s - loss: 0.4571 - accuracy: 0.7927 - val_loss: 0.4631 - val_accuracy: 0.7725 - 528ms/epoch - 26ms/step\n",
      "Epoch 13/50\n",
      "20/20 - 1s - loss: 0.4651 - accuracy: 0.8038 - val_loss: 0.4586 - val_accuracy: 0.7725 - 854ms/epoch - 43ms/step\n",
      "Epoch 14/50\n",
      "20/20 - 1s - loss: 0.4444 - accuracy: 0.8166 - val_loss: 0.4544 - val_accuracy: 0.7678 - 860ms/epoch - 43ms/step\n",
      "Epoch 15/50\n",
      "20/20 - 1s - loss: 0.4504 - accuracy: 0.8150 - val_loss: 0.4527 - val_accuracy: 0.7725 - 741ms/epoch - 37ms/step\n",
      "Epoch 16/50\n",
      "20/20 - 1s - loss: 0.4358 - accuracy: 0.8134 - val_loss: 0.4504 - val_accuracy: 0.7725 - 616ms/epoch - 31ms/step\n",
      "Epoch 17/50\n",
      "20/20 - 1s - loss: 0.4633 - accuracy: 0.8038 - val_loss: 0.4482 - val_accuracy: 0.7678 - 796ms/epoch - 40ms/step\n",
      "Epoch 18/50\n",
      "20/20 - 1s - loss: 0.4400 - accuracy: 0.8198 - val_loss: 0.4466 - val_accuracy: 0.7773 - 674ms/epoch - 34ms/step\n",
      "Epoch 19/50\n",
      "20/20 - 1s - loss: 0.4349 - accuracy: 0.8182 - val_loss: 0.4443 - val_accuracy: 0.7773 - 505ms/epoch - 25ms/step\n",
      "Epoch 20/50\n",
      "20/20 - 1s - loss: 0.4383 - accuracy: 0.8198 - val_loss: 0.4430 - val_accuracy: 0.7725 - 632ms/epoch - 32ms/step\n",
      "Epoch 21/50\n",
      "20/20 - 1s - loss: 0.4211 - accuracy: 0.8230 - val_loss: 0.4421 - val_accuracy: 0.7773 - 780ms/epoch - 39ms/step\n",
      "Epoch 22/50\n",
      "20/20 - 1s - loss: 0.4283 - accuracy: 0.8134 - val_loss: 0.4399 - val_accuracy: 0.7820 - 684ms/epoch - 34ms/step\n",
      "Epoch 23/50\n",
      "20/20 - 1s - loss: 0.4294 - accuracy: 0.8150 - val_loss: 0.4386 - val_accuracy: 0.7820 - 571ms/epoch - 29ms/step\n",
      "Epoch 24/50\n",
      "20/20 - 1s - loss: 0.4289 - accuracy: 0.8246 - val_loss: 0.4364 - val_accuracy: 0.7867 - 550ms/epoch - 27ms/step\n",
      "Epoch 25/50\n",
      "20/20 - 1s - loss: 0.4527 - accuracy: 0.8118 - val_loss: 0.4355 - val_accuracy: 0.7820 - 506ms/epoch - 25ms/step\n",
      "Epoch 26/50\n",
      "20/20 - 1s - loss: 0.4351 - accuracy: 0.8198 - val_loss: 0.4339 - val_accuracy: 0.7820 - 575ms/epoch - 29ms/step\n",
      "Epoch 27/50\n",
      "20/20 - 1s - loss: 0.4454 - accuracy: 0.8214 - val_loss: 0.4332 - val_accuracy: 0.7962 - 609ms/epoch - 30ms/step\n",
      "Epoch 28/50\n",
      "20/20 - 1s - loss: 0.4193 - accuracy: 0.8246 - val_loss: 0.4320 - val_accuracy: 0.7867 - 615ms/epoch - 31ms/step\n",
      "Epoch 29/50\n",
      "20/20 - 1s - loss: 0.4203 - accuracy: 0.8325 - val_loss: 0.4297 - val_accuracy: 0.7867 - 541ms/epoch - 27ms/step\n",
      "Epoch 30/50\n",
      "20/20 - 1s - loss: 0.4165 - accuracy: 0.8278 - val_loss: 0.4294 - val_accuracy: 0.7867 - 582ms/epoch - 29ms/step\n",
      "Epoch 31/50\n",
      "20/20 - 1s - loss: 0.4173 - accuracy: 0.8341 - val_loss: 0.4277 - val_accuracy: 0.7867 - 676ms/epoch - 34ms/step\n",
      "Epoch 32/50\n",
      "20/20 - 1s - loss: 0.4185 - accuracy: 0.8182 - val_loss: 0.4266 - val_accuracy: 0.7867 - 562ms/epoch - 28ms/step\n",
      "Epoch 33/50\n",
      "20/20 - 1s - loss: 0.4138 - accuracy: 0.8309 - val_loss: 0.4263 - val_accuracy: 0.7867 - 634ms/epoch - 32ms/step\n",
      "Epoch 34/50\n",
      "20/20 - 1s - loss: 0.4192 - accuracy: 0.8325 - val_loss: 0.4274 - val_accuracy: 0.7915 - 580ms/epoch - 29ms/step\n",
      "Epoch 35/50\n",
      "20/20 - 1s - loss: 0.4070 - accuracy: 0.8278 - val_loss: 0.4258 - val_accuracy: 0.7915 - 616ms/epoch - 31ms/step\n",
      "Epoch 36/50\n",
      "20/20 - 1s - loss: 0.4193 - accuracy: 0.8166 - val_loss: 0.4246 - val_accuracy: 0.7915 - 543ms/epoch - 27ms/step\n",
      "Epoch 37/50\n",
      "20/20 - 0s - loss: 0.4147 - accuracy: 0.8357 - val_loss: 0.4240 - val_accuracy: 0.7962 - 483ms/epoch - 24ms/step\n",
      "Epoch 38/50\n",
      "20/20 - 0s - loss: 0.4286 - accuracy: 0.8309 - val_loss: 0.4247 - val_accuracy: 0.7962 - 477ms/epoch - 24ms/step\n",
      "Epoch 39/50\n",
      "20/20 - 1s - loss: 0.4158 - accuracy: 0.8325 - val_loss: 0.4248 - val_accuracy: 0.7962 - 557ms/epoch - 28ms/step\n",
      "Epoch 40/50\n",
      "20/20 - 1s - loss: 0.4227 - accuracy: 0.8341 - val_loss: 0.4239 - val_accuracy: 0.8009 - 688ms/epoch - 34ms/step\n",
      "Epoch 41/50\n",
      "20/20 - 1s - loss: 0.4077 - accuracy: 0.8246 - val_loss: 0.4237 - val_accuracy: 0.8009 - 529ms/epoch - 26ms/step\n",
      "Epoch 42/50\n",
      "20/20 - 1s - loss: 0.4181 - accuracy: 0.8214 - val_loss: 0.4216 - val_accuracy: 0.8009 - 524ms/epoch - 26ms/step\n",
      "Epoch 43/50\n",
      "20/20 - 1s - loss: 0.4106 - accuracy: 0.8389 - val_loss: 0.4212 - val_accuracy: 0.8009 - 514ms/epoch - 26ms/step\n",
      "Epoch 44/50\n",
      "20/20 - 1s - loss: 0.4007 - accuracy: 0.8405 - val_loss: 0.4213 - val_accuracy: 0.8057 - 618ms/epoch - 31ms/step\n",
      "Epoch 45/50\n",
      "20/20 - 1s - loss: 0.4180 - accuracy: 0.8214 - val_loss: 0.4203 - val_accuracy: 0.8009 - 556ms/epoch - 28ms/step\n",
      "Epoch 46/50\n",
      "20/20 - 1s - loss: 0.4151 - accuracy: 0.8341 - val_loss: 0.4199 - val_accuracy: 0.8057 - 622ms/epoch - 31ms/step\n",
      "Epoch 47/50\n",
      "20/20 - 1s - loss: 0.4171 - accuracy: 0.8293 - val_loss: 0.4199 - val_accuracy: 0.8104 - 793ms/epoch - 40ms/step\n",
      "Epoch 48/50\n",
      "20/20 - 1s - loss: 0.4084 - accuracy: 0.8357 - val_loss: 0.4194 - val_accuracy: 0.8104 - 659ms/epoch - 33ms/step\n",
      "Epoch 49/50\n",
      "20/20 - 1s - loss: 0.3919 - accuracy: 0.8325 - val_loss: 0.4200 - val_accuracy: 0.8104 - 643ms/epoch - 32ms/step\n",
      "Epoch 50/50\n",
      "20/20 - 1s - loss: 0.4192 - accuracy: 0.8198 - val_loss: 0.4204 - val_accuracy: 0.8152 - 804ms/epoch - 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25996d8b410>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model.fit(\n",
    "    preprocessed_train_ds, epochs=50, validation_data=preprocessed_val_ds, verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4bee61d9-dd2c-45a7-af07-79da59cdbd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000025990ACCFE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = training_model.predict(preprocessed_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d5261aa2-11df-4315-a997-38435092921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (predictions > 0.5).astype(int).reshape(-1,)\n",
    "label_values = []\n",
    "\n",
    "# Iterate through preprocessed_val_ds to collect labels\n",
    "for _, labels in preprocessed_test_ds.as_numpy_iterator():\n",
    "    label_values.extend(labels)\n",
    "\n",
    "# Convert the collected labels to a NumPy array\n",
    "label_values = np.array(label_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3a2b26d9-6526-4c38-a780-fa08fa11a8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81        34\n",
      "           1       0.65      0.68      0.67        19\n",
      "\n",
      "    accuracy                           0.75        53\n",
      "   macro avg       0.73      0.74      0.74        53\n",
      "weighted avg       0.76      0.75      0.76        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_values, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e537189a-2be8-402e-8252-3fa2cffc4fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'female'], dtype=object)>, 'age': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([25])>, 'n_siblings_spouses': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>, 'parch': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>, 'fare': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([5])>, 'class': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Third'], dtype=object)>, 'deck': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Unknown'], dtype=object)>, 'embark_town': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Southampton'], dtype=object)>, 'alone': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'y'], dtype=object)>}\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "[[0.61438274]]\n",
      "This particular passenger had a 61.44% probability of surviving, as evaluated by our model.\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    \"sex\": \"female\",\n",
    "    \"age\": 25,\n",
    "    \"n_siblings_spouses\": 0,\n",
    "    \"parch\": 0,\n",
    "    \"fare\": 5,\n",
    "    \"class\": \"Third\",\n",
    "    \"deck\": \"Unknown\",\n",
    "    \"embark_town\": \"Southampton\",\n",
    "    \"alone\": \"y\",\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "print(input_dict)\n",
    "predictions = inference_model.predict(input_dict)\n",
    "print(predictions)\n",
    "\n",
    "print(\n",
    "    f\"This particular passenger had a {100 * predictions[0][0]:.2f}% probability \"\n",
    "    \"of surviving, as evaluated by our model.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9740b9e-7f1b-466d-9020-73e14ec7b139",
   "metadata": {},
   "source": [
    "# Inference model for the SQ_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cba28120-307a-4112-bbbf-8b823dd0633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the inference model with the same architecture as sq_model\n",
    "inference_model = keras.Sequential()\n",
    "inference_model.add(keras.layers.Dense(32, activation=\"relu\", input_shape=encoded_features.shape[1:]))\n",
    "inference_model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Load the trained weights from the training model (sq_model) into the inference model\n",
    "inference_model.set_weights(sq_model.get_weights())\n",
    "\n",
    "# Now you can use inference_model for making predictions with the trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8b931910-56c2-431b-82db-c3ff9430ff79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = inference_model.predict(preprocessed_test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ec1664a5-4074-4315-9407-1223a71587cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (predictions > 0.5).astype(int).reshape(-1,)\n",
    "label_values = []\n",
    "\n",
    "# Iterate through preprocessed_val_ds to collect labels\n",
    "for _, labels in preprocessed_test_ds.as_numpy_iterator():\n",
    "    label_values.extend(labels)\n",
    "\n",
    "# Convert the collected labels to a NumPy array\n",
    "label_values = np.array(label_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d85bf44c-ba73-4147-a2b5-040eeeff70ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        34\n",
      "           1       0.63      0.63      0.63        19\n",
      "\n",
      "    accuracy                           0.74        53\n",
      "   macro avg       0.71      0.71      0.71        53\n",
      "weighted avg       0.74      0.74      0.74        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_values, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cf47d84c-8e0b-475e-8731-7fb9683a4050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 12ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        34\n",
      "           1       0.63      0.63      0.63        19\n",
      "\n",
      "    accuracy                           0.74        53\n",
      "   macro avg       0.71      0.71      0.71        53\n",
      "weighted avg       0.74      0.74      0.74        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_sq = sq_model.predict(preprocessed_test_ds)\n",
    "predictions_sq = (predictions_sq > 0.5).astype(int).reshape(-1,)\n",
    "print(classification_report(label_values, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9993e573-3ef8-4d45-819f-e8f349db7f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
